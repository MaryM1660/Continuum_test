import React, { useState, useEffect } from 'react';
import {
  View,
  StyleSheet,
  TouchableOpacity,
  Alert,
} from 'react-native';
import { StatusBar } from 'expo-status-bar';
import { useNavigation } from '@react-navigation/native';
import { StackNavigationProp } from '@react-navigation/stack';
import { Cloud } from '../components/Cloud';
import { MicButtons } from '../components/MicButtons';
import { useTheme } from '../theme/useTheme';
import { Audio } from 'expo-av';
import { Platform } from 'react-native';
import { COACH_PHRASES, speakText } from '../services/mockVoice';
import { microphoneService } from '../services/microphone';
import { voiceRecognitionService } from '../services/voiceRecognition';
import { llmService } from '../services/llmService';
import { RootStackParamList } from '../../App';
import { ScreenContainer, Container, Stack, Section } from '../components/layout';
import { Text } from '../components/typography';
import { Icon } from '../components/icons';
import { VolumeSlider } from '../components/VolumeSlider';
import { DeviceSelector } from '../components/DeviceSelector';

type TalkScreenNavigationProp = StackNavigationProp<RootStackParamList, 'Talk'>;

interface TalkScreenProps {
  onOpenDrawer?: () => void;
}

type OnboardingStep = 1 | 2 | 3 | 'complete';

export const TalkScreen: React.FC<TalkScreenProps> = ({ onOpenDrawer }) => {
  const theme = useTheme();
  const navigation = useNavigation<TalkScreenNavigationProp>();
  const [onboardingStep, setOnboardingStep] = useState<OnboardingStep>(1);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isMuted, setIsMuted] = useState(true);
  const [hasMicPermission, setHasMicPermission] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [isWaitingForUser, setIsWaitingForUser] = useState(false);
  const [volume, setVolume] = useState(0.8); // 0-1
  const [audioDevice, setAudioDevice] = useState<string>('speaker'); // 'speaker', 'headphones', 'bluetooth'
  const [inputDevice, setInputDevice] = useState<string>('phone'); // 'phone', 'headphones'
  const [outputDevice, setOutputDevice] = useState<string>('speaker'); // 'speaker', 'headphones'
  const [showVolumeSlider, setShowVolumeSlider] = useState(false);
  const [showDeviceSelector, setShowDeviceSelector] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recognizedText, setRecognizedText] = useState<string>('');
  const [isProcessingLLM, setIsProcessingLLM] = useState(false);
  const [displayText, setDisplayText] = useState<string>(''); // –¢–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —ç–∫—Ä–∞–Ω–µ
  const [speechText, setSpeechText] = useState<string>(''); // –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏
  const wasMutedBeforeProcessing = React.useRef<boolean>(false);

  // –ó–∞–ø—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
  const requestMicPermission = async (): Promise<boolean> => {
    try {
      if (Platform.OS === 'web') {
        // –ù–∞ –≤–µ–± –∏—Å–ø–æ–ª—å–∑—É–µ–º Web API
        try {
          const granted = await microphoneService.requestPermission();
          if (granted) {
            setHasMicPermission(true);
            console.log('Microphone permission granted');
            return true;
          } else {
            console.warn('Microphone permission denied by user');
            // –ù–∞ –≤–µ–± –≤—Å–µ —Ä–∞–≤–Ω–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º, –Ω–æ –±–µ–∑ –¥–æ—Å—Ç—É–ø–∞ –∫ –º–∏–∫—Ä–æ—Ñ–æ–Ω—É
            setHasMicPermission(false);
            return true; // –†–∞–∑—Ä–µ—à–∞–µ–º –ø—Ä–æ–¥–æ–ª–∂–µ–Ω–∏–µ –¥–∞–∂–µ –±–µ–∑ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
          }
        } catch (error) {
          console.error('Error requesting mic permission:', error);
          // –ù–∞ –≤–µ–± –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
          setHasMicPermission(false);
          return true;
        }
      } else {
        // –ù–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º expo-av
        const { status } = await Audio.requestPermissionsAsync();
        if (status === 'granted') {
          setHasMicPermission(true);
          return true;
        } else {
          Alert.alert(
            'Microphone Permission',
            'This app requires microphone access to function. Please grant permission in settings.',
            [
              { text: 'Cancel', style: 'cancel' },
              { text: 'Retry', onPress: requestMicPermission },
            ]
          );
          return false;
        }
      }
    } catch (error) {
      console.error('Error requesting mic permission:', error);
      // –ù–∞ –≤–µ–± –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
      if (Platform.OS === 'web') {
        setHasMicPermission(false);
        return true;
      }
      return false;
    }
  };

  // –û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
  const speak = async (text: string) => {
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Ä–µ—á—å, –µ—Å–ª–∏ –æ–Ω–∞ –∏–¥–µ—Ç
    if (Platform.OS === 'web') {
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
      }
    } else {
      const Speech = require('expo-speech');
      Speech.stop();
    }
    
    setIsSpeaking(true);
    try {
      // –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–≤—É–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ä–µ—á–∏
      const interval = setInterval(() => {
        setAudioLevel(Math.random() * 0.5 + 0.3);
      }, 100);

      await speakText(text, volume);
      
      clearInterval(interval);
      setAudioLevel(0);
    } catch (error) {
      console.error('Error speaking:', error);
    } finally {
      setIsSpeaking(false);
    }
  };

  // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —ç–∫—Ä–∞–Ω–∞
  useEffect(() => {
    const checkMicPermission = async () => {
      if (Platform.OS === 'web') {
        // –ù–∞ –≤–µ–± –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ navigator.permissions
        try {
          if (navigator.permissions && navigator.permissions.query) {
            const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
            if (result.state === 'granted') {
              setHasMicPermission(true);
              // –ï—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –µ—Å—Ç—å, –∏–¥–µ–º –Ω–∞ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥ –∏–ª–∏ –≥–ª–∞–≤–Ω—ã–π —ç–∫—Ä–∞–Ω
              if (onboardingStep === 1) {
                setIsWaitingForUser(true);
              }
            } else {
              // –ï—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–µ—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º STEP 3
              setOnboardingStep(3);
              setIsWaitingForUser(true);
            }
          } else {
            // –ï—Å–ª–∏ API permissions –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ –ø–æ–ø—ã—Ç–∫—É –¥–æ—Å—Ç—É–ø–∞
            // –ù–æ –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            setOnboardingStep(1);
            setIsWaitingForUser(true);
          }
        } catch (error) {
          console.log('Permission check not available, starting with onboarding');
          setOnboardingStep(1);
          setIsWaitingForUser(true);
        }
      } else {
        // –ù–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ expo-av
        try {
          const { status } = await Audio.getPermissionsAsync();
          if (status === 'granted') {
            setHasMicPermission(true);
            if (onboardingStep === 1) {
              setIsWaitingForUser(true);
            }
          } else {
            setOnboardingStep(3);
            setIsWaitingForUser(true);
          }
        } catch (error) {
          console.log('Error checking permission, starting with onboarding');
          setOnboardingStep(1);
          setIsWaitingForUser(true);
        }
      }
    };

    checkMicPermission();
  }, []);

  // Cleanup –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
  useEffect(() => {
    return () => {
      if (Platform.OS === 'web') {
        microphoneService.stopRecording();
        voiceRecognitionService.stopListening();
      }
    };
  }, []);

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ —à–∞–≥–æ–≤ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
  const handleStep1 = async () => {
    if (!isWaitingForUser) return;
    
    // –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —à–∞–≥ 2 –±–µ–∑ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
    setOnboardingStep(2);
    setIsWaitingForUser(true); // –°—Ä–∞–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É
  };

  const handleStep2 = async () => {
    if (!isWaitingForUser) return;
    
    // –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —à–∞–≥ 3 –±–µ–∑ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
    setOnboardingStep(3);
    setIsWaitingForUser(true); // –°—Ä–∞–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  };

  const handleStep3 = async () => {
    if (isSpeaking || !isWaitingForUser) return;
    
    console.log('handleStep3 called - requesting microphone permission');
    setIsWaitingForUser(false);
    
    try {
      // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
      const granted = await requestMicPermission();
      console.log('Microphone permission result:', granted);
      
      // –ë–ï–ó —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ù–ï –ø–µ—Ä–µ—Ö–æ–¥–∏–º –¥–∞–ª—å—à–µ
      if (!granted) {
        setIsWaitingForUser(true);
        if (Platform.OS !== 'web') {
          Alert.alert(
            'Microphone Permission Required',
            'This app requires microphone access to function. Please grant permission to continue.',
            [
              { text: 'Cancel', style: 'cancel', onPress: () => setIsWaitingForUser(true) },
              { text: 'Retry', onPress: handleStep3 },
            ]
          );
        } else {
          Alert.alert(
            'Microphone Permission Required',
            'Please allow microphone access in your browser settings to continue.',
            [{ text: 'OK', onPress: () => setIsWaitingForUser(true) }]
          );
        }
        return;
      }
      
      // –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—ã–π —ç–∫—Ä–∞–Ω
      setHasMicPermission(true);
      setOnboardingStep('complete');
      setIsMuted(false);
      
      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM
      try {
        llmService.resetConversation();
      } catch (error) {
        console.warn('Error initializing LLM:', error);
      }
      
      // –ü–µ—Ä–µ—Ö–æ–¥ –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É —ç–∫—Ä–∞–Ω—É —Å –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ–º
      setTimeout(() => {
        console.log('Calling handleMainScreenWelcome');
        handleMainScreenWelcome();
      }, 300);
    } catch (error) {
      console.error('Error in handleStep3:', error);
      // –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Å—Ç–∞–µ–º—Å—è –Ω–∞ STEP 3
      setIsWaitingForUser(true);
      Alert.alert(
        'Error',
        'Failed to request microphone permission. Please try again.',
        [{ text: 'OK', onPress: () => setIsWaitingForUser(true) }]
      );
    }
  };

  const handleMainScreenWelcome = async () => {
    console.log('handleMainScreenWelcome called');
    try {
      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –°–†–ê–ó–£ (–¥–æ –æ–∑–≤—É—á–∫–∏)
      setDisplayText(`${COACH_PHRASES.main.welcome}\n\n${COACH_PHRASES.main.chooseOption}`);
      
      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏
      const welcomeSpeech = `${COACH_PHRASES.main.welcome} ${COACH_PHRASES.main.chooseOption}`;
      setSpeechText(welcomeSpeech);
      
      // –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –°–†–ê–ó–£
      setIsWaitingForUser(true);
      console.log('UI should be visible now');
      
      // –û–∑–≤—É—á–∏–≤–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –Ω–µ –±–ª–æ–∫–∏—Ä—É—è UI
      (async () => {
        try {
          await speak(welcomeSpeech);
        } catch (error) {
          console.warn('Speech error in welcome:', error);
          // UI —É–∂–µ –ø–æ–∫–∞–∑–∞–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
        }
      })();
    } catch (error) {
      console.error('Error in handleMainScreenWelcome:', error);
      // –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º UI
      setIsWaitingForUser(true);
    }
  };

  const handleToggleMute = async () => {
    console.log('handleToggleMute called, current isMuted:', isMuted);
    const newMutedState = !isMuted;
    console.log('newMutedState:', newMutedState);
    
    if (Platform.OS === 'web') {
      if (newMutedState) {
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        console.log('Stopping recording and recognition');
        microphoneService.stopRecording();
        voiceRecognitionService.stopListening();
        setIsRecording(false);
        setRecognizedText('');
        setIsMuted(true);
      } else {
        // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, –µ—Å–ª–∏ –µ—â–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω–æ
        if (!hasMicPermission) {
          console.log('No microphone permission, redirecting to STEP 3');
          // –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ STEP 3 –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
          setOnboardingStep(3);
          setIsWaitingForUser(true);
          return;
        }
        
        console.log('Starting recording and recognition');
        
        // –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ —Å —Ä–µ–∞–ª—å–Ω—ã–º –º–∏–∫—Ä–æ—Ñ–æ–Ω–æ–º
        const micStarted = await microphoneService.startRecording((level) => {
          setAudioLevel(level);
        });

        if (micStarted && voiceRecognitionService.isAvailable()) {
          const recognitionStarted = await voiceRecognitionService.startListening(
            (result) => {
              console.log('Recognition result:', result);
              setRecognizedText(result.text);
              
              // –í—ã–≤–æ–¥–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Å–æ–ª—å
              if (result.text && result.text.trim()) {
                console.log('üé§ [MICROPHONE] Recognized text:', result.text);
                if (result.isFinal) {
                  console.log('‚úÖ [MICROPHONE] Final result:', result.text);
                } else {
                  console.log('‚è≥ [MICROPHONE] Interim result:', result.text);
                }
              }
              
              // –ü—Ä–∏ —Ñ–∏–Ω–∞–ª—å–Ω–æ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç–µ —Å—Ä–∞–∑—É –æ—Ç–ø—Ä–∞–≤–ª—è–µ–º (—á–µ—Ä–µ–∑ –∫–æ—Ä–æ—Ç–∫—É—é –ø–∞—É–∑—É)
              if (result.isFinal && result.text.trim()) {
                console.log('Final result received, will send to LLM:', result.text);
                // –ù–µ–±–æ–ª—å—à–∞—è –∑–∞–¥–µ—Ä–∂–∫–∞ –ø–µ—Ä–µ–¥ –æ—Ç–ø—Ä–∞–≤–∫–æ–π
                setTimeout(() => {
                  handleUserSpeech(result.text);
                }, 500);
              }
            },
            (error) => {
              console.error('Voice recognition error:', error);
              // –ü—Ä–∏ –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö –æ—à–∏–±–∫–∞—Ö (no-speech, aborted) –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º
              // Recognition –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å—Ç–∏—Ç—Å—è —á–µ—Ä–µ–∑ onend
              if (error.message && (error.message.includes('no-speech') || error.message.includes('aborted'))) {
                console.log('Recognition will auto-restart');
              } else {
                setIsRecording(false);
              }
            },
            // Callback –ø—Ä–∏ –ø–∞—É–∑–µ (fallback, –µ—Å–ª–∏ —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –Ω–µ –ø—Ä–∏—à–µ–ª)
            (finalText: string) => {
              console.log('Silence callback triggered, final text:', finalText);
              if (finalText.trim()) {
                console.log('üé§ [MICROPHONE] Silence detected, final text:', finalText);
                handleUserSpeech(finalText);
              }
            },
            2000 // 2 —Å–µ–∫—É–Ω–¥—ã —Ç–∏—à–∏–Ω—ã (fallback)
          );
          
          if (recognitionStarted) {
            setIsRecording(true);
            setIsMuted(false);
            console.log('Recording and recognition started');
          } else {
            microphoneService.stopRecording();
            Alert.alert('Error', 'Could not start voice recognition. Please try again.');
          }
        } else {
          if (!micStarted) {
            Alert.alert('Error', 'Could not access microphone. Please check permissions.');
          } else if (!voiceRecognitionService.isAvailable()) {
            Alert.alert('Not Supported', 'Voice recognition is not available in your browser. Please use Chrome or Edge.');
          }
        }
      }
    } else {
      // –ù–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
      setIsMuted(newMutedState);
    }
  };

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –Ω–∞ –±—ç–∫ (–ø–æ–∫–∞ —ç–º—É–ª—è—Ü–∏—è)
  const logToBackend = async (type: 'voice' | 'button', content: string) => {
    // TODO: –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π API –≤—ã–∑–æ–≤
    console.log(`üìù [BACKEND LOG] Type: ${type}, Content:`, content);
    // –í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç fetch('/api/log', { method: 'POST', body: { type, content } })
  };

  const handleUserSpeech = async (text: string) => {
    if (isProcessingLLM || !text.trim()) {
      console.log('Skipping speech processing:', { isProcessingLLM, text: text.trim() });
      return;
    }

    console.log('üé§ [MICROPHONE] Processing user speech:', text);
    console.log('üìù [BACKEND] Logging to backend - Type: voice, Content:', text);
    
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –±—ç–∫ (–Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ —ç–∫—Ä–∞–Ω–µ)
    await logToBackend('voice', text);
    
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    wasMutedBeforeProcessing.current = isMuted;
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if (Platform.OS === 'web') {
      microphoneService.stopRecording();
      voiceRecognitionService.stopListening();
      setIsRecording(false);
    }

    setIsProcessingLLM(true);
    setRecognizedText(''); // –û—á–∏—â–∞–µ–º, –Ω–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º

    try {
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM
      const response = await llmService.chat(text);
      console.log('LLM response:', response);

      if (response.text) {
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–Ω–æ –Ω–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ)
        setSpeechText(response.text);
        // –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç —Å —Ç–µ–∫—É—â–µ–π –≥—Ä–æ–º–∫–æ—Å—Ç—å—é
        await speak(response.text);
      } else {
        const errorMsg = "I'm sorry, I didn't get a response. Could you try again?";
        setSpeechText(errorMsg);
        await speak(errorMsg);
      }
    } catch (error) {
      console.error('Error processing speech:', error);
      const errorMsg = "I'm sorry, I didn't catch that. Could you repeat?";
      setSpeechText(errorMsg);
      await speak(errorMsg);
    } finally {
      setIsProcessingLLM(false);
      // –ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å (–µ—Å–ª–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –±—ã–ª –≤–∫–ª—é—á–µ–Ω)
      if (Platform.OS === 'web' && hasMicPermission && !wasMutedBeforeProcessing.current) {
        // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –≤–∫–ª—é—á–µ–Ω –¥–æ –æ–±—Ä–∞–±–æ—Ç–∫–∏
        // –ï—Å–ª–∏ –±—ã–ª –≤–∫–ª—é—á–µ–Ω, –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –ø–æ—Å–ª–µ –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏
        setTimeout(async () => {
          console.log('Resuming recording after response');
          // –ü–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
          const micStarted = await microphoneService.startRecording((level) => {
            setAudioLevel(level);
          });

          if (micStarted && voiceRecognitionService.isAvailable()) {
            const recognitionStarted = await voiceRecognitionService.startListening(
              (result) => {
                // –û–±–Ω–æ–≤–ª—è–µ–º recognizedText –¥–ª—è –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è, –Ω–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º
                setRecognizedText(result.text);
                
                // –í—ã–≤–æ–¥–∏–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –≤ –∫–æ–Ω—Å–æ–ª—å
                if (result.text && result.text.trim()) {
                  console.log('üé§ [MICROPHONE] Recognized text:', result.text);
                  if (result.isFinal) {
                    console.log('‚úÖ [MICROPHONE] Final result:', result.text);
                  } else {
                    console.log('‚è≥ [MICROPHONE] Interim result:', result.text);
                  }
                }
              },
              (error) => {
                console.error('Voice recognition error:', error);
                setIsRecording(false);
              },
              (finalText: string) => {
                if (finalText.trim()) {
                  console.log('üé§ [MICROPHONE] Silence detected, final text:', finalText);
                  handleUserSpeech(finalText);
                }
              },
              3000
            );
            
            if (recognitionStarted) {
              setIsRecording(true);
            }
          }
        }, 1500); // –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∏–µ —Ä–µ—á–∏
      }
    }
  };

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–º–µ–Ω–µ–Ω–∏—è –≥—Ä–æ–º–∫–æ—Å—Ç–∏
  const handleSoundLevel = () => {
    setShowVolumeSlider(true);
  };

  const handleVolumeChange = (newVolume: number) => {
    console.log('Volume changed to:', newVolume);
    setVolume(newVolume);
    // –ì—Ä–æ–º–∫–æ—Å—Ç—å –±—É–¥–µ—Ç –ø—Ä–∏–º–µ–Ω–µ–Ω–∞ –ø—Ä–∏ —Å–ª–µ–¥—É—é—â–µ–º speak()
    // –ú–æ–∂–Ω–æ —Ç–∞–∫–∂–µ –ø—Ä–∏–º–µ–Ω–∏—Ç—å –∫ —Ç–µ–∫—É—â–µ–π —Ä–µ—á–∏, –µ—Å–ª–∏ –æ–Ω–∞ –∏–¥–µ—Ç
    if (Platform.OS === 'web' && 'speechSynthesis' in window && isSpeaking) {
      // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—É—â—É—é —Ä–µ—á—å –∏ –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞–µ–º —Å –Ω–æ–≤–æ–π –≥—Ä–æ–º–∫–æ—Å—Ç—å—é
      // (–≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ —ç—Ç–æ —Å–ª–æ–∂–Ω–æ, –ø–æ—ç—Ç–æ–º—É –ø—Ä–æ—Å—Ç–æ –ø—Ä–∏–º–µ–Ω—è–µ–º –∫ —Å–ª–µ–¥—É—é—â–µ–π)
    }
  };

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ –≤—ã–±–æ—Ä–∞ –∞—É–¥–∏–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–∞
  const handleMicSelect = () => {
    if (Platform.OS === 'web') {
      // –ù–∞ –≤–µ–± –≤—ã–±–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤ –æ–≥—Ä–∞–Ω–∏—á–µ–Ω –±—Ä–∞—É–∑–µ—Ä–æ–º
      // –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ç–∏–≤–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ
      Alert.alert(
        'Device Selection',
        'On web, audio devices are managed by your browser. To change devices:\n\n' +
        '1. Click the lock icon in your browser address bar\n' +
        '2. Go to Site Settings\n' +
        '3. Change microphone and speaker settings\n\n' +
        'Or use your system settings to set default devices.',
        [{ text: 'OK' }]
      );
    } else {
      setShowDeviceSelector(true);
    }
  };

  const handleInputDeviceSelect = (deviceId: string) => {
    setInputDevice(deviceId);
    // –ù–∞ –≤–µ–± —ç—Ç–æ —ç–º—É–ª—è—Ü–∏—è, —Ä–µ–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç –ø–µ—Ä–µ–∑–∞–ø—É—Å–∫–∞ –∑–∞–ø–∏—Å–∏
    if (Platform.OS === 'web' && isRecording) {
      Alert.alert(
        'Device Changed',
        'To apply the new microphone, please stop and restart recording.',
        [{ text: 'OK' }]
      );
    }
  };

  const handleOutputDeviceSelect = (deviceId: string) => {
    setOutputDevice(deviceId);
    // –ù–∞ –≤–µ–± —ç—Ç–æ —ç–º—É–ª—è—Ü–∏—è, —Ä–µ–∞–ª—å–Ω–æ–µ –ø–µ—Ä–µ–∫–ª—é—á–µ–Ω–∏–µ —Ç—Ä–µ–±—É–µ—Ç —Å–∏—Å—Ç–µ–º–Ω—ã—Ö –Ω–∞—Å—Ç—Ä–æ–µ–∫
    if (Platform.OS === 'web') {
      Alert.alert(
        'Output Device',
        'On web, speaker output is controlled by your system. Please change the default audio output in your system settings.',
        [{ text: 'OK' }]
      );
    }
  };

  const handleOption1 = async () => {
    // –ö–Ω–æ–ø–∫–∏ –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∑–∞–ø–∏—Å–∏
    const optionText = "Follow the coach's plan";
    
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –Ω–∞ –±—ç–∫
    await logToBackend('button', optionText);
    
    const speechResponse = "Great! Let's follow the coach's plan. I'll guide you through a structured conversation about your career.";
    
    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–Ω–æ –Ω–µ –º–µ–Ω—è–µ–º displayText, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ)
    setSpeechText(speechResponse);
    
    // –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
    await speak(speechResponse);
  };

  const handleOption2 = async () => {
    // –ö–Ω–æ–ø–∫–∏ –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∑–∞–ø–∏—Å–∏
    const optionText = "Discuss your topic or document";
    
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –Ω–∞ –±—ç–∫
    await logToBackend('button', optionText);
    
    const speechResponse = "Perfect! Let's discuss your topic or document. What would you like to talk about?";
    
    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–Ω–æ –Ω–µ –º–µ–Ω—è–µ–º displayText, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ)
    setSpeechText(speechResponse);
    
    // –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
    await speak(speechResponse);
  };

  const renderOnboardingContent = () => {
    switch (onboardingStep) {
      case 1:
        return (
          <Container>
            <Stack gap={theme.spacing['2xl']} align="center">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {COACH_PHRASES.onboarding.step1}
              </Text>
              {isWaitingForUser && (
                <TouchableOpacity
                  onPress={handleStep1}
                  disabled={isSpeaking}
                  style={[
                    styles.button,
                    { 
                      backgroundColor: theme.primary,
                      opacity: isSpeaking ? 0.5 : 1,
                    }
                  ]}
                >
                  <Text variant="buttonLarge" style={{ color: theme.primaryContrast }}>
                    Hi
                  </Text>
                </TouchableOpacity>
              )}
            </Stack>
          </Container>
        );
      case 2:
        return (
          <Container>
            <Stack gap={theme.spacing['2xl']} align="center">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {COACH_PHRASES.onboarding.step2}
              </Text>
              {isWaitingForUser && (
                <TouchableOpacity
                  onPress={handleStep2}
                  disabled={isSpeaking}
                  style={[
                    styles.button,
                    { 
                      backgroundColor: theme.primary,
                      opacity: isSpeaking ? 0.5 : 1,
                    }
                  ]}
                >
                  <Text variant="buttonLarge" style={{ color: theme.primaryContrast }}>
                    Ok
                  </Text>
                </TouchableOpacity>
              )}
            </Stack>
          </Container>
        );
      case 3:
        return (
          <Container>
            <Stack gap={theme.spacing['2xl']} align="center">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {COACH_PHRASES.onboarding.step3}
              </Text>
              {isWaitingForUser && (
                <TouchableOpacity
                  onPress={handleStep3}
                  disabled={isSpeaking}
                  style={[
                    styles.button,
                    { 
                      backgroundColor: theme.primary,
                      opacity: isSpeaking ? 0.5 : 1,
                    }
                  ]}
                >
                  <Text variant="buttonLarge" style={{ color: theme.primaryContrast }}>
                    Turn on the mic
                  </Text>
                </TouchableOpacity>
              )}
            </Stack>
          </Container>
        );
      default:
        return null;
    }
  };

  const renderMainContent = () => {
    if (onboardingStep !== 'complete') return null;

    return (
      <Container>
        <Stack gap={theme.spacing['2xl']} align="center">
          {/* –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Å—Ç–∞—Ç—É—Å –æ–±—Ä–∞–±–æ—Ç–∫–∏ */}
          {isProcessingLLM && (
            <Section marginTop="none">
              <Text variant="caption" align="center" style={{ maxWidth: '90%', color: theme.textSecondary }}>
                Thinking...
              </Text>
            </Section>
          )}

          {/* –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è (–æ—Ç–æ–±—Ä–∞–∂–∞–µ—Ç—Å—è —Å—Ä–∞–∑—É, –¥–æ –æ–∑–≤—É—á–∫–∏) */}
          {displayText && (
            <Section marginTop="none">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {displayText}
              </Text>
            </Section>
          )}

          {/* –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—é –ø—Ä–∏ –∑–∞–ø–∏—Å–∏ */}
          {isRecording && (
            <Section marginTop="none">
              <Text variant="body" align="center" style={{ maxWidth: '90%' }}>
                Listening... Speak now
              </Text>
            </Section>
          )}
          
          {/* –ö–Ω–æ–ø–∫–∏ –æ–ø—Ü–∏–π –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∑–∞–ø–∏—Å–∏ */}
          <Section marginTop="none">
            <Stack gap={theme.spacing.base} align="stretch">
              <TouchableOpacity
                onPress={handleOption1}
                style={[
                  styles.optionButton,
                  { 
                    backgroundColor: theme.surface,
                    borderColor: theme.border,
                  }
                ]}
              >
                <Text variant="body" align="center">
                  {COACH_PHRASES.main.option1}
                </Text>
              </TouchableOpacity>
              <TouchableOpacity
                onPress={handleOption2}
                style={[
                  styles.optionButton,
                  { 
                    backgroundColor: theme.surface,
                    borderColor: theme.border,
                  }
                ]}
              >
                <Text variant="body" align="center">
                  {COACH_PHRASES.main.option2}
                </Text>
              </TouchableOpacity>
            </Stack>
          </Section>

          <Section marginTop="none">
            <MicButtons
              theme={theme}
              isMuted={isMuted}
              onToggleMute={handleToggleMute}
              onMicSelect={handleMicSelect}
              onSoundLevel={handleSoundLevel}
            />
          </Section>
        </Stack>
      </Container>
    );
  };

  return (
    <ScreenContainer>
      <StatusBar style={theme.background === '#FFFFFF' ? 'dark' : 'light'} />
      
      {/* –ö–Ω–æ–ø–∫–∞ –º–µ–Ω—é (drawer) */}
      {onboardingStep === 'complete' && (
        <TouchableOpacity
          onPress={() => onOpenDrawer?.()}
          style={[styles.menuButton, { backgroundColor: theme.surface }]}
        >
          <Icon name="Bars3" size={28} />
        </TouchableOpacity>
      )}
      
      {/* –û–±–ª–∞–∫–æ - —Ñ–∏–∫—Å–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –≤ –≤–µ—Ä—Ö–Ω–µ–π —á–∞—Å—Ç–∏ */}
      <View style={[styles.cloudContainer, { backgroundColor: 'transparent' }]}>
        <Cloud
          theme={theme}
          isSpeaking={isSpeaking}
          audioLevel={audioLevel}
        />
      </View>

      {/* –ö–æ–Ω—Ç–µ–Ω—Ç - —Å –ø—Ä–∞–≤–∏–ª—å–Ω—ã–º–∏ –æ—Ç—Å—Ç—É–ø–∞–º–∏ —Å–Ω–∏–∑—É */}
      <View style={styles.contentWrapper}>
        {onboardingStep !== 'complete' ? renderOnboardingContent() : renderMainContent()}
      </View>

      {/* –°–ª–∞–π–¥–µ—Ä –≥—Ä–æ–º–∫–æ—Å—Ç–∏ */}
      <VolumeSlider
        visible={showVolumeSlider}
        volume={volume}
        onClose={() => setShowVolumeSlider(false)}
        onVolumeChange={handleVolumeChange}
      />

      {/* –°–µ–ª–µ–∫—Ç–æ—Ä —É—Å—Ç—Ä–æ–π—Å—Ç–≤ */}
      <DeviceSelector
        visible={showDeviceSelector}
        selectedInputDevice={inputDevice}
        selectedOutputDevice={outputDevice}
        onClose={() => setShowDeviceSelector(false)}
        onInputDeviceSelect={handleInputDeviceSelect}
        onOutputDeviceSelect={handleOutputDeviceSelect}
      />
    </ScreenContainer>
  );
};

const styles = StyleSheet.create({
  menuButton: {
    position: 'absolute',
    top: 50, // spacing['2xl'] + spacing.lg
    left: 20, // spacing.lg
    width: 48, // spacing['4xl']
    height: 48, // spacing['4xl']
    borderRadius: 24, // spacing['4xl'] / 2
    justifyContent: 'center',
    alignItems: 'center',
    zIndex: 1000,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 }, // spacing.xs
    shadowOpacity: 0.15,
    shadowRadius: 8, // spacing.sm
    elevation: 8,
  },
  cloudContainer: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    height: '50%',
    justifyContent: 'center',
    alignItems: 'center',
    zIndex: 1,
    backgroundColor: 'transparent',
    overflow: 'visible', // –ß—Ç–æ–±—ã –æ–±–ª–∞—á–∫–æ –Ω–µ –æ–±—Ä–µ–∑–∞–ª–æ—Å—å
  },
  contentWrapper: {
    flex: 1,
    justifyContent: 'flex-end',
    paddingBottom: 40, // spacing['3xl']
    zIndex: 2,
    paddingTop: '50%', // –û—Ç—Å—Ç—É–ø —Å–≤–µ—Ä—Ö—É, —á—Ç–æ–±—ã –∫–æ–Ω—Ç–µ–Ω—Ç –Ω–µ –Ω–∞–ª–µ–∑–∞–ª –Ω–∞ –æ–±–ª–∞–∫–æ
  },
  bodyText: {
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É –∏–∑ theme
    textAlign: 'center',
    maxWidth: '90%',
  },
  button: {
    paddingHorizontal: 40, // spacing['3xl']
    paddingVertical: 18, // spacing.lg - spacing.xs
    borderRadius: 28, // spacing['2xl'] - spacing.xs
    minWidth: 140,
    alignItems: 'center',
    shadowColor: '#1F7EB9',
    shadowOffset: { width: 0, height: 4 }, // spacing.xs
    shadowOpacity: 0.3,
    shadowRadius: 8, // spacing.sm
    elevation: 8,
  },
  buttonText: {
    color: '#FFFFFF',
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É –∏–∑ theme
  },
  optionButton: {
    padding: 24, // spacing.xl
    borderRadius: 16, // spacing.base
    borderWidth: 1.5,
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 }, // spacing.xs / 2
    shadowOpacity: 0.1,
    shadowRadius: 4, // spacing.xs
    elevation: 3,
  },
  optionText: {
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É –∏–∑ theme
  },
});

