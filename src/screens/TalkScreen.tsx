import React, { useState, useEffect } from 'react';
import {
  View,
  StyleSheet,
  TouchableOpacity,
  Alert,
} from 'react-native';
import { StatusBar } from 'expo-status-bar';
import { useNavigation } from '@react-navigation/native';
import { StackNavigationProp } from '@react-navigation/stack';
import { MicButtons } from '../components/MicButtons';
import { useTheme } from '../theme/useTheme';
import { Audio } from 'expo-av';
import { Platform } from 'react-native';
import { COACH_PHRASES, speakText } from '../services/mockVoice';
import { microphoneService } from '../services/microphone';
import { voiceRecognitionService } from '../services/voiceRecognition';
import { llmService } from '../services/llmService';
import { RootStackParamList } from '../../App';
import { ScreenContainer, Container, Stack, Section } from '../components/layout';
import { Text } from '../components/typography';
import { Icon } from '../components/icons';
import { LiquidGlassButton } from '../components/LiquidGlassButton';

type TalkScreenNavigationProp = StackNavigationProp<RootStackParamList, 'Talk'>;

interface TalkScreenProps {
  onOpenDrawer?: () => void;
}

type OnboardingStep = 1 | 2 | 3 | 'complete';

export const TalkScreen: React.FC<TalkScreenProps> = ({ onOpenDrawer }) => {
  const theme = useTheme();
  // navigation –∏ onOpenDrawer –º–æ–≥—É—Ç –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å—Å—è –≤ –±—É–¥—É—â–µ–º –¥–ª—è –Ω–∞–≤–∏–≥–∞—Ü–∏–∏
  const [onboardingStep, setOnboardingStep] = useState<OnboardingStep>(1);
  const [isSpeaking, setIsSpeaking] = useState(false);
  const [isMuted, setIsMuted] = useState(true);
  const [hasMicPermission, setHasMicPermission] = useState(false);
  const [audioLevel, setAudioLevel] = useState(0);
  const [isWaitingForUser, setIsWaitingForUser] = useState(false);
  const [isRecording, setIsRecording] = useState(false);
  const [recognizedText, setRecognizedText] = useState<string>('');
  const [isProcessingLLM, setIsProcessingLLM] = useState(false);
  const [displayText, setDisplayText] = useState<string>(''); // –¢–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è –Ω–∞ —ç–∫—Ä–∞–Ω–µ
  const [speechText, setSpeechText] = useState<string>(''); // –¢–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏
  
  // Refs
  const wasMutedBeforeProcessing = React.useRef<boolean>(false);
  const lastInterimText = React.useRef<string>('');
  const lastInterimTime = React.useRef<number>(0);
  const silenceTimeoutRef = React.useRef<NodeJS.Timeout | null>(null);
  const isMutedRef = React.useRef<boolean>(true); // Ref –¥–ª—è –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è isMuted
  
  // –°–∏–Ω—Ö—Ä–æ–Ω–∏–∑–∏—Ä—É–µ–º ref —Å state
  React.useEffect(() => {
    isMutedRef.current = isMuted;
  }, [isMuted]);

  // –ó–∞–ø—Ä–æ—Å —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
  const requestMicPermission = async (): Promise<boolean> => {
    try {
      if (Platform.OS === 'web') {
        // –í–ê–ñ–ù–û: –ù–∞ –≤–µ–± –ù–ï –≤—ã–∑—ã–≤–∞–µ–º getUserMedia() –æ—Ç–¥–µ–ª—å–Ω–æ!
        // Speech Recognition –°–ê–ú –∑–∞–ø—Ä–æ—Å–∏—Ç —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø—Ä–∏ start()
        // –ü—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º –¥–æ—Å—Ç—É–ø–Ω–æ—Å—Ç—å API
        if (navigator.mediaDevices && navigator.mediaDevices.getUserMedia) {
          console.log('‚úÖ [PERMISSION] MediaDevices API available - Speech Recognition will request permission');
          // –ù–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∑–¥–µ—Å—å - –ø—É—Å—Ç—å Speech Recognition —Å–¥–µ–ª–∞–µ—Ç —ç—Ç–æ
          // –ü—Ä–æ—Å—Ç–æ –ø–æ–º–µ—á–∞–µ–º, —á—Ç–æ API –¥–æ—Å—Ç—É–ø–µ–Ω
          setHasMicPermission(true); // –£—Å–ª–æ–≤–Ω–æ true, —Ä–µ–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∑–∞–ø—Ä–æ—Å–∏—Ç Speech Recognition
          return true;
        } else {
          console.warn('‚ùå [PERMISSION] MediaDevices API not available');
          setHasMicPermission(false);
          return false;
        }
      } else {
        // –ù–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –∏—Å–ø–æ–ª—å–∑—É–µ–º expo-av
        const { status } = await Audio.requestPermissionsAsync();
        if (status === 'granted') {
          setHasMicPermission(true);
          return true;
        } else {
          Alert.alert(
            'Microphone Permission',
            'This app requires microphone access to function. Please grant permission in settings.',
            [
              { text: 'Cancel', style: 'cancel' },
              { text: 'Retry', onPress: requestMicPermission },
            ]
          );
          return false;
        }
      }
    } catch (error) {
      console.error('Error requesting mic permission:', error);
      // –ù–∞ –≤–µ–± –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º –¥–∞–∂–µ –ø—Ä–∏ –æ—à–∏–±–∫–µ
      if (Platform.OS === 'web') {
        setHasMicPermission(false);
        return true;
      }
      return false;
    }
  };

  // –û–∑–≤—É—á–∏–≤–∞–Ω–∏–µ —Ç–µ–∫—Å—Ç–∞
  const speak = async (text: string) => {
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â—É—é —Ä–µ—á—å, –µ—Å–ª–∏ –æ–Ω–∞ –∏–¥–µ—Ç
    if (Platform.OS === 'web') {
      if ('speechSynthesis' in window) {
        window.speechSynthesis.cancel();
      }
    } else {
      const Speech = require('expo-speech');
      Speech.stop();
    }
    
    setIsSpeaking(true);
    try {
      // –í–∏–∑—É–∞–ª–∏–∑–∞—Ü–∏—è –∑–≤—É–∫–∞ –≤–æ –≤—Ä–µ–º—è —Ä–µ—á–∏
      const interval = setInterval(() => {
        setAudioLevel(Math.random() * 0.5 + 0.3);
      }, 100);

      await speakText(text);
      
      clearInterval(interval);
      setAudioLevel(0);
    } catch (error) {
      console.error('Error speaking:', error);
    } finally {
      setIsSpeaking(false);
    }
  };

  // –ü—Ä–æ–≤–µ—Ä–∫–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ —ç–∫—Ä–∞–Ω–∞
  useEffect(() => {
    const checkMicPermission = async () => {
      if (Platform.OS === 'web') {
        // –ù–∞ –≤–µ–± –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ navigator.permissions
        try {
          if (navigator.permissions && navigator.permissions.query) {
            const result = await navigator.permissions.query({ name: 'microphone' as PermissionName });
            if (result.state === 'granted') {
              setHasMicPermission(true);
              // –ï—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –µ—Å—Ç—å, –∏–¥–µ–º –Ω–∞ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥ –∏–ª–∏ –≥–ª–∞–≤–Ω—ã–π —ç–∫—Ä–∞–Ω
              if (onboardingStep === 1) {
                setIsWaitingForUser(true);
              }
            } else {
              // –ï—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –Ω–µ—Ç, –ø–æ–∫–∞–∑—ã–≤–∞–µ–º STEP 3
              setOnboardingStep(3);
              setIsWaitingForUser(true);
            }
          } else {
            // –ï—Å–ª–∏ API permissions –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ –ø–æ–ø—ã—Ç–∫—É –¥–æ—Å—Ç—É–ø–∞
            // –ù–æ –Ω–µ –∑–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
            setOnboardingStep(1);
            setIsWaitingForUser(true);
          }
        } catch (error) {
          console.log('Permission check not available, starting with onboarding');
          setOnboardingStep(1);
          setIsWaitingForUser(true);
        }
      } else {
        // –ù–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ–≤–µ—Ä—è–µ–º —á–µ—Ä–µ–∑ expo-av
        try {
          const { status } = await Audio.getPermissionsAsync();
          if (status === 'granted') {
            setHasMicPermission(true);
            if (onboardingStep === 1) {
              setIsWaitingForUser(true);
            }
          } else {
            setOnboardingStep(3);
            setIsWaitingForUser(true);
          }
        } catch (error) {
          console.log('Error checking permission, starting with onboarding');
          setOnboardingStep(1);
          setIsWaitingForUser(true);
        }
      }
    };

    checkMicPermission();
  }, []);

  // Cleanup –ø—Ä–∏ —Ä–∞–∑–º–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–∏
  useEffect(() => {
    return () => {
      if (Platform.OS === 'web') {
        try {
          microphoneService.stopRecording();
        } catch (error) {
          // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ, –µ—Å–ª–∏ —Å–µ—Ä–≤–∏—Å –Ω–µ –∑–∞–ø—É—â–µ–Ω
          console.log('Cleanup: microphoneService already stopped');
        }
        try {
          voiceRecognitionService.stopListening();
        } catch (error) {
          // –ò–≥–Ω–æ—Ä–∏—Ä—É–µ–º –æ—à–∏–±–∫–∏ –ø—Ä–∏ –æ—Å—Ç–∞–Ω–æ–≤–∫–µ, –µ—Å–ª–∏ —Å–µ—Ä–≤–∏—Å –Ω–µ –∑–∞–ø—É—â–µ–Ω
          console.log('Cleanup: voiceRecognitionService already stopped');
        }
      }
    };
  }, []);

  // –û–±—Ä–∞–±–æ—Ç–∫–∞ —à–∞–≥–æ–≤ –æ–Ω–±–æ—Ä–¥–∏–Ω–≥–∞
  const handleStep1 = async () => {
    if (!isWaitingForUser) return;
    
    // –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —à–∞–≥ 2 –±–µ–∑ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
    setOnboardingStep(2);
    setIsWaitingForUser(true); // –°—Ä–∞–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É
  };

  const handleStep2 = async () => {
    if (!isWaitingForUser) return;
    
    // –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ —à–∞–≥ 3 –±–µ–∑ –æ–∑–≤—É—á–∏–≤–∞–Ω–∏—è
    setOnboardingStep(3);
    setIsWaitingForUser(true); // –°—Ä–∞–∑—É –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–Ω–æ–ø–∫—É –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞
  };

  const handleStep3 = async () => {
    if (isSpeaking || !isWaitingForUser) return;
    
    console.log('handleStep3 called - requesting microphone permission');
    setIsWaitingForUser(false);
    
    try {
      // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–µ–∞–ª—å–Ω–æ–µ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –Ω–∞ –º–∏–∫—Ä–æ—Ñ–æ–Ω
      const granted = await requestMicPermission();
      console.log('Microphone permission result:', granted);
      
      // –ë–ï–ó —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è –ù–ï –ø–µ—Ä–µ—Ö–æ–¥–∏–º –¥–∞–ª—å—à–µ
      if (!granted) {
        setIsWaitingForUser(true);
        if (Platform.OS !== 'web') {
          Alert.alert(
            'Microphone Permission Required',
            'This app requires microphone access to function. Please grant permission to continue.',
            [
              { text: 'Cancel', style: 'cancel', onPress: () => setIsWaitingForUser(true) },
              { text: 'Retry', onPress: handleStep3 },
            ]
          );
        } else {
          Alert.alert(
            'Microphone Permission Required',
            'Please allow microphone access in your browser settings to continue.',
            [{ text: 'OK', onPress: () => setIsWaitingForUser(true) }]
          );
        }
        return;
      }
      
      // –¢–æ–ª—å–∫–æ –µ—Å–ª–∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ –ø–æ–ª—É—á–µ–Ω–æ, –ø–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ –≥–ª–∞–≤–Ω—ã–π —ç–∫—Ä–∞–Ω
      setHasMicPermission(true);
      setOnboardingStep('complete');
      // –ù–ï –≤–∫–ª—é—á–∞–µ–º –º–∏–∫—Ä–æ—Ñ–æ–Ω –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ - –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å —Å–∞–º –≤–∫–ª—é—á–∏—Ç –∫–Ω–æ–ø–∫–æ–π
      setIsMuted(true);
      
      // –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM
      try {
        llmService.resetConversation();
      } catch (error) {
        console.warn('Error initializing LLM:', error);
      }
      
      // –ü–µ—Ä–µ—Ö–æ–¥ –∫ –æ—Å–Ω–æ–≤–Ω–æ–º—É —ç–∫—Ä–∞–Ω—É —Å –æ–∑–≤—É—á–∏–≤–∞–Ω–∏–µ–º
      setTimeout(() => {
        console.log('Calling handleMainScreenWelcome');
        handleMainScreenWelcome();
      }, 300);
    } catch (error) {
      console.error('Error in handleStep3:', error);
      // –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –æ—Å—Ç–∞–µ–º—Å—è –Ω–∞ STEP 3
      setIsWaitingForUser(true);
      Alert.alert(
        'Error',
        'Failed to request microphone permission. Please try again.',
        [{ text: 'OK', onPress: () => setIsWaitingForUser(true) }]
      );
    }
  };

  const handleMainScreenWelcome = async () => {
    console.log('handleMainScreenWelcome called');
    try {
      // –ù–ï —É—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º displayText - —Ç–µ–∫—Å—Ç –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ —ç–∫—Ä–∞–Ω–µ, —Ç–æ–ª—å–∫–æ –æ–∑–≤—É—á–∏–≤–∞–µ–º
      // setDisplayText(`${COACH_PHRASES.main.welcome}\n\n${COACH_PHRASES.main.chooseOption}`);
      
      // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –æ–∑–≤—É—á–∫–∏
      const welcomeSpeech = `${COACH_PHRASES.main.welcome} ${COACH_PHRASES.main.chooseOption}`;
      setSpeechText(welcomeSpeech);
      
      // –í—Å–µ–≥–¥–∞ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –∫–æ–Ω—Ç–µ–Ω—Ç –°–†–ê–ó–£
      setIsWaitingForUser(true);
      console.log('UI should be visible now');
      
      // –û–∑–≤—É—á–∏–≤–∞–µ–º –∞—Å–∏–Ω—Ö—Ä–æ–Ω–Ω–æ, –Ω–µ –±–ª–æ–∫–∏—Ä—É—è UI
      (async () => {
        try {
          await speak(welcomeSpeech);
        } catch (error) {
          console.warn('Speech error in welcome:', error);
          // UI —É–∂–µ –ø–æ–∫–∞–∑–∞–Ω, –ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Ä–∞–±–æ—Ç—É
        }
      })();
    } catch (error) {
      console.error('Error in handleMainScreenWelcome:', error);
      // –í –ª—é–±–æ–º —Å–ª—É—á–∞–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º UI
      setIsWaitingForUser(true);
    }
  };

  // –ï–¥–∏–Ω—ã–π callback –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏—è
  // –ò—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –∏ –ø—Ä–∏ –ø–µ—Ä–≤–æ–Ω–∞—á–∞–ª—å–Ω–æ–º –∑–∞–ø—É—Å–∫–µ, –∏ –ø—Ä–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏–∏ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –∫–æ—É—á–∞
  const createRecognitionCallback = () => {
    return (result: any) => {
      console.log('‚úÖ [MAIN] Recognition result received!', result);
      console.log('‚úÖ [MAIN] Text:', result.text, 'isFinal:', result.isFinal);
      
      // –û–±–Ω–æ–≤–ª—è–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è
      setRecognizedText(result.text);
      
      // –í–ê–ñ–ù–û: –õ–æ–≥–∏—Ä—É–µ–º –í–°–ï —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã, –æ—Å–æ–±–µ–Ω–Ω–æ —Ñ–∏–Ω–∞–ª—å–Ω—ã–µ
      if (result.isFinal) {
        console.log('üéâüéâüéâ [MAIN] FINAL RESULT RECEIVED:', result.text);
        console.log('üéâüéâüéâ [MAIN] FULL SENTENCE:', result.text);
        console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
        console.log('üé§ –í–´ –°–ö–ê–ó–ê–õ–ò (–§–ò–ù–ê–õ–¨–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢):', result.text);
        console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
        
        // –û—á–∏—â–∞–µ–º —Ç–∞–π–º–µ—Ä —Ç–∏—à–∏–Ω—ã
        if (silenceTimeoutRef.current) {
          clearTimeout(silenceTimeoutRef.current);
          silenceTimeoutRef.current = null;
        }
        lastInterimText.current = '';
        lastInterimTime.current = 0;
        
        // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM
        console.log('üì§ [MAIN] Sending to LLM:', result.text);
        setTimeout(() => {
          handleUserSpeech(result.text);
        }, 500);
      } else {
        // –ü–†–û–ú–ï–ñ–£–¢–û–ß–ù–´–ô –†–ï–ó–£–õ–¨–¢–ê–¢ - –≤—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å
        console.log('‚è≥ [MAIN] Interim result:', result.text);
        console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
        console.log('üé§ –í–´ –ì–û–í–û–†–ò–¢–ï (–ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π):', result.text);
        console.log('‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ');
        
        // –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –¥–ª—è –¥–µ—Ç–µ–∫—Ü–∏–∏ —Ç–∏—à–∏–Ω—ã
        const currentText = result.text.trim();
        if (currentText) {
          lastInterimText.current = currentText;
          lastInterimTime.current = Date.now();
          
          // –û—á–∏—â–∞–µ–º –ø—Ä–µ–¥—ã–¥—É—â–∏–π —Ç–∞–π–º–µ—Ä
          if (silenceTimeoutRef.current) {
            clearTimeout(silenceTimeoutRef.current);
            silenceTimeoutRef.current = null;
          }
          
          // –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ —Å—á–∏—Ç–∞—Ç—å —ç—Ç–æ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–µ–º
          const hasSentenceEnd = /[.!?]\s*$/.test(currentText);
          const wordCount = currentText.split(/\s+/).length;
          
          // –ï—Å–ª–∏ –µ—Å—Ç—å –∑–Ω–∞–∫ –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ò –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ —Å–ª–æ–≤ (–º–∏–Ω–∏–º—É–º 5), —Å—á–∏—Ç–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–º
          if (hasSentenceEnd && wordCount >= 5) {
            console.log('üìù [MAIN] Sentence end detected, treating interim as final');
            console.log('üéâüéâüéâ [MAIN] FINAL SENTENCE (from sentence end):', currentText);
            console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
            console.log('üé§ –í–´ –°–ö–ê–ó–ê–õ–ò (–§–ò–ù–ê–õ–¨–ù–´–ô - –ø–æ –∑–Ω–∞–∫—É –∫–æ–Ω—Ü–∞):', currentText);
            console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
            
            setRecognizedText(currentText);
            setAudioLevel(0);
            
            console.log('üì§ [MAIN] Sending to LLM (from sentence end):', currentText);
            setTimeout(() => {
              handleUserSpeech(currentText);
            }, 500);
            
            lastInterimText.current = '';
            lastInterimTime.current = 0;
          } else if (wordCount >= 50) {
            // –ï—Å–ª–∏ –Ω–µ—Ç –∫–æ–Ω—Ü–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è, –Ω–æ —Ç–µ–∫—Å—Ç –¥–ª–∏–Ω–Ω—ã–π (50+ —Å–ª–æ–≤), —Ç–æ–∂–µ —Å—á–∏—Ç–∞–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—ã–º
            console.log('üìè [MAIN] Long text detected (', wordCount, ' words), treating interim as final');
            console.log('üéâüéâüéâ [MAIN] FINAL SENTENCE (from length):', currentText);
            console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
            console.log('üé§ –í–´ –°–ö–ê–ó–ê–õ–ò (–§–ò–ù–ê–õ–¨–ù–´–ô - –ø–æ –¥–ª–∏–Ω–µ):', currentText);
            console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
            
            setRecognizedText(currentText);
            setAudioLevel(0);
            
            console.log('üì§ [MAIN] Sending to LLM (from length):', currentText);
            setTimeout(() => {
              handleUserSpeech(currentText);
            }, 500);
            
            lastInterimText.current = '';
            lastInterimTime.current = 0;
          } else {
            // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–∞–π–º–µ—Ä –Ω–∞ —Å–ª—É—á–∞–π —Ç–∏—à–∏–Ω—ã
            silenceTimeoutRef.current = setTimeout(() => {
              const timeSinceLastUpdate = Date.now() - lastInterimTime.current;
              const savedText = lastInterimText.current;
              
              if (savedText && savedText.trim() && timeSinceLastUpdate >= 3000) {
                console.log('‚è∞ [MAIN] Silence detected (', timeSinceLastUpdate, 'ms), treating interim as final');
                console.log('üéâüéâüéâ [MAIN] FINAL SENTENCE (from silence):', savedText);
                console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
                console.log('üé§ –í–´ –°–ö–ê–ó–ê–õ–ò (–§–ò–ù–ê–õ–¨–ù–´–ô - –ø–æ —Ç–∏—à–∏–Ω–µ):', savedText);
                console.log('‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê');
                
                setRecognizedText(savedText);
                setAudioLevel(0);
                
                console.log('üì§ [MAIN] Sending to LLM (from silence):', savedText);
                setTimeout(() => {
                  handleUserSpeech(savedText);
                }, 500);
              }
            }, 3000);
          }
        }
      }
    };
  };

  // –ï–¥–∏–Ω—ã–π callback –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ –æ—à–∏–±–æ–∫
  const createErrorCallback = () => {
    return (error: Error) => {
      console.error('‚ùå [MAIN] Recognition error:', error);
      // no-speech –∏ aborted - –Ω–æ—Ä–º–∞–ª—å–Ω—ã–µ —Å–æ–±—ã—Ç–∏—è, –Ω–µ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º
      if (error.message && !error.message.includes('no-speech') && !error.message.includes('aborted')) {
        // –¢–æ–ª—å–∫–æ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –æ—à–∏–±–∫–∏ –æ—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞—é—Ç –∑–∞–ø–∏—Å—å
        console.error('‚ùå [MAIN] Critical error, stopping:', error);
        setIsRecording(false);
        setAudioLevel(0);
      }
    };
  };

  const handleToggleMute = async () => {
    console.log('üîò [BUTTON] handleToggleMute called, current isMuted:', isMuted);
    const newMutedState = !isMuted;
    console.log('üîò [BUTTON] newMutedState (will be):', newMutedState);
    
    if (Platform.OS === 'web') {
      if (newMutedState) {
        // –í–´–ö–õ–Æ–ß–ê–ï–ú –º–∏–∫—Ä–æ—Ñ–æ–Ω
        // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –∏ —Ä–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ
        console.log('Stopping recording and recognition');
        // –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º microphoneService - —Ç–æ–ª—å–∫–æ Speech Recognition
        voiceRecognitionService.stopListening();
        setIsRecording(false);
        setRecognizedText('');
        setAudioLevel(0);
        setIsMuted(true);
      } else {
        // –í–ö–õ–Æ–ß–ê–ï–ú –º–∏–∫—Ä–æ—Ñ–æ–Ω
        console.log('üîò [BUTTON] Enabling microphone...');
        
        // –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ, –µ—Å–ª–∏ –µ—â–µ –Ω–µ –ø–æ–ª—É—á–µ–Ω–æ
        if (!hasMicPermission) {
          console.log('‚ö†Ô∏è [BUTTON] No microphone permission, redirecting to STEP 3');
          // –ü–µ—Ä–µ—Ö–æ–¥–∏–º –Ω–∞ STEP 3 –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏—è
          setOnboardingStep(3);
          setIsWaitingForUser(true);
          return;
        }
        
        console.log('üöÄ [BUTTON] Starting recording and recognition');
        console.log('üöÄ [BUTTON] voiceRecognitionService.isAvailable():', voiceRecognitionService.isAvailable());
        
        // Speech Recognition –°–ê–ú –∑–∞–ø—Ä–æ—Å–∏—Ç –º–∏–∫—Ä–æ—Ñ–æ–Ω –ø—Ä–∏ start()
        // –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º microphoneService - —ç—Ç–æ —Å–æ–∑–¥–∞–µ—Ç –∫–æ–Ω—Ñ–ª–∏–∫—Ç!
        if (voiceRecognitionService.isAvailable()) {
          console.log('‚úÖ [BUTTON] Service is available, calling startListening...');
          console.log('üìû [BUTTON] About to call voiceRecognitionService.startListening...');
          const recognitionStarted = await voiceRecognitionService.startListening(
            createRecognitionCallback(),
            createErrorCallback()
          );
          
          console.log('üìû [BUTTON] startListening returned:', recognitionStarted);
          if (recognitionStarted) {
            setIsRecording(true);
            setIsMuted(false);
            console.log('‚úÖ [MAIN] Recognition started successfully! Microphone will be requested by Speech Recognition');
          } else {
            console.error('‚ùå [MAIN] Recognition failed to start!');
            Alert.alert(
              'Error', 
              'Could not start voice recognition. Please check:\n' +
              '1. Microphone permissions\n' +
              '2. Browser support (Chrome/Edge recommended)\n' +
              '3. Internet connection (required for speech recognition)'
            );
          }
        } else {
          Alert.alert('Not Supported', 'Voice recognition is not available in your browser. Please use Chrome or Edge.');
        }
      }
    } else {
      // –ù–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–æ—Å—Ç–æ –ø–µ—Ä–µ–∫–ª—é—á–∞–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ
      setIsMuted(newMutedState);
    }
  };

  // –§—É–Ω–∫—Ü–∏—è –¥–ª—è –∑–∞–ø–∏—Å–∏ –Ω–∞ –±—ç–∫ (–ø–æ–∫–∞ —ç–º—É–ª—è—Ü–∏—è)
  const logToBackend = async (type: 'voice' | 'button', content: string) => {
    // TODO: –ó–∞–º–µ–Ω–∏—Ç—å –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–π API –≤—ã–∑–æ–≤
    console.log(`üìù [BACKEND LOG] Type: ${type}, Content:`, content);
    // –í –±—É–¥—É—â–µ–º –∑–¥–µ—Å—å –±—É–¥–µ—Ç fetch('/api/log', { method: 'POST', body: { type, content } })
  };

  const handleUserSpeech = async (text: string) => {
    if (isProcessingLLM || !text.trim()) {
      console.log('Skipping speech processing:', { isProcessingLLM, text: text.trim() });
      return;
    }

    console.log('üé§ [MICROPHONE] Processing user speech:', text);
    console.log('üìù [BACKEND] Logging to backend - Type: voice, Content:', text);
    
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–∞—Å–ø–æ–∑–Ω–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –Ω–∞ –±—ç–∫ (–Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –Ω–∞ —ç–∫—Ä–∞–Ω–µ)
    await logToBackend('voice', text);
    
    // –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ—Å—Ç–æ—è–Ω–∏–µ –º–∏–∫—Ä–æ—Ñ–æ–Ω–∞ –ø–µ—Ä–µ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–æ–π
    wasMutedBeforeProcessing.current = isMuted;
    
    // –û—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –∑–∞–ø–∏—Å—å –≤–æ –≤—Ä–µ–º—è –æ–±—Ä–∞–±–æ—Ç–∫–∏
    if (Platform.OS === 'web') {
      // –ù–ï –∏—Å–ø–æ–ª—å–∑—É–µ–º microphoneService - —Ç–æ–ª—å–∫–æ Speech Recognition
      voiceRecognitionService.stopListening();
      setIsRecording(false);
      setAudioLevel(0);
    }

    setIsProcessingLLM(true);
    setRecognizedText(''); // –û—á–∏—â–∞–µ–º, –Ω–æ –Ω–µ –ø–æ–∫–∞–∑—ã–≤–∞–µ–º

    try {
      // –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –≤ LLM
      const response = await llmService.chat(text);
      console.log('LLM response:', response);

      if (response.text) {
        // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–Ω–æ –Ω–µ –¥–ª—è –æ—Ç–æ–±—Ä–∞–∂–µ–Ω–∏—è, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ)
        setSpeechText(response.text);
        // –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç —Å —Ç–µ–∫—É—â–µ–π –≥—Ä–æ–º–∫–æ—Å—Ç—å—é
        await speak(response.text);
      } else {
        const errorMsg = "I'm sorry, I didn't get a response. Could you try again?";
        setSpeechText(errorMsg);
        await speak(errorMsg);
      }
    } catch (error) {
      console.error('Error processing speech:', error);
      const errorMsg = "I'm sorry, I didn't catch that. Could you repeat?";
      setSpeechText(errorMsg);
      await speak(errorMsg);
    } finally {
      setIsProcessingLLM(false);
      // –ü–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å (–µ—Å–ª–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –ù–ï –≤—ã–∫–ª—é—á–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º)
      // –í–ê–ñ–ù–û: –ò—Å–ø–æ–ª—å–∑—É–µ–º ref –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –∞–∫—Ç—É–∞–ª—å–Ω–æ–≥–æ —Å–æ—Å—Ç–æ—è–Ω–∏—è isMuted –≤ setTimeout
      if (Platform.OS === 'web' && hasMicPermission) {
        // –ú–∏–∫—Ä–æ—Ñ–æ–Ω –¥–æ–ª–∂–µ–Ω –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å —Ä–∞–±–æ—Ç–∞—Ç—å - –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å –ø–æ—Å–ª–µ –Ω–µ–±–æ–ª—å—à–æ–π –∑–∞–¥–µ—Ä–∂–∫–∏
        setTimeout(async () => {
          // –ü—Ä–æ–≤–µ—Ä—è–µ–º –∞–∫—Ç—É–∞–ª—å–Ω–æ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ —á–µ—Ä–µ–∑ ref
          const currentIsMuted = isMutedRef.current;
          console.log('üîÑ [RESUME] Resuming recording after response, isMuted (from ref):', currentIsMuted);
          
          // –ï—Å–ª–∏ –º–∏–∫—Ä–æ—Ñ–æ–Ω –Ω–µ –≤—ã–∫–ª—é—á–µ–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º, –≤–æ–∑–æ–±–Ω–æ–≤–ª—è–µ–º –∑–∞–ø–∏—Å—å
          if (!currentIsMuted && voiceRecognitionService.isAvailable()) {
            console.log('üîÑ [RESUME] Starting recognition...');
            const recognitionStarted = await voiceRecognitionService.startListening(
              createRecognitionCallback(),
              createErrorCallback()
            );
            
            if (recognitionStarted) {
              setIsRecording(true);
              console.log('‚úÖ [RESUME] Recording resumed successfully');
            } else {
              console.error('‚ùå [RESUME] Failed to resume recording');
            }
          } else {
            console.log('‚è∏Ô∏è [RESUME] Not resuming - isMuted:', currentIsMuted, 'hasMicPermission:', hasMicPermission, 'isAvailable:', voiceRecognitionService.isAvailable());
          }
        }, 1000); // –ó–∞–¥–µ—Ä–∂–∫–∞ 1 —Å–µ–∫—É–Ω–¥–∞ –ø–æ—Å–ª–µ –æ—Ç–≤–µ—Ç–∞ –∫–æ—É—á–∞
      } else {
        console.log('‚è∏Ô∏è [RESUME] Not resuming - Platform:', Platform.OS, 'hasMicPermission:', hasMicPermission);
      }
    }
  };



  const handleOption1 = async () => {
    // –ö–Ω–æ–ø–∫–∏ –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∑–∞–ø–∏—Å–∏
    const optionText = "Follow the coach's plan";
    
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –Ω–∞ –±—ç–∫
    await logToBackend('button', optionText);
    
    const speechResponse = "Great! Let's follow the coach's plan. I'll guide you through a structured conversation about your career.";
    
    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–Ω–æ –Ω–µ –º–µ–Ω—è–µ–º displayText, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ)
    setSpeechText(speechResponse);
    
    // –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
    await speak(speechResponse);
  };

  const handleOption2 = async () => {
    // –ö–Ω–æ–ø–∫–∏ –≤—Å–µ–≥–¥–∞ –∞–∫—Ç–∏–≤–Ω—ã, –Ω–µ–∑–∞–≤–∏—Å–∏–º–æ –æ—Ç –∑–∞–ø–∏—Å–∏
    const optionText = "Discuss your topic or document";
    
    // –ó–∞–ø–∏—Å—ã–≤–∞–µ–º –≤—ã–±–æ—Ä –Ω–∞ –±—ç–∫
    await logToBackend('button', optionText);
    
    const speechResponse = "Perfect! Let's discuss your topic or document. What would you like to talk about?";
    
    // –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º —Ç–µ–∫—Å—Ç –¥–ª—è –æ–∑–≤—É—á–∫–∏ (–Ω–æ –Ω–µ –º–µ–Ω—è–µ–º displayText, –µ—Å–ª–∏ –Ω–µ –Ω—É–∂–Ω–æ)
    setSpeechText(speechResponse);
    
    // –û–∑–≤—É—á–∏–≤–∞–µ–º –æ—Ç–≤–µ—Ç
    await speak(speechResponse);
  };

  const renderOnboardingContent = () => {
    switch (onboardingStep) {
      case 1:
        return (
          <Container>
            <Stack gap={theme.spacing['2xl']} align="center">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {COACH_PHRASES.onboarding.step1}
              </Text>
              {isWaitingForUser && (
                <LiquidGlassButton
                  onPress={handleStep1}
                  disabled={isSpeaking}
                  variant="primary"
                  theme={theme}
                  textVariant="buttonLarge"
                >
                  Hi
                </LiquidGlassButton>
              )}
            </Stack>
          </Container>
        );
      case 2:
        return (
          <Container>
            <Stack gap={theme.spacing['2xl']} align="center">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {COACH_PHRASES.onboarding.step2}
              </Text>
              {isWaitingForUser && (
                <LiquidGlassButton
                  onPress={handleStep2}
                  disabled={isSpeaking}
                  variant="primary"
                  theme={theme}
                  textVariant="buttonLarge"
                >
                  Ok
                </LiquidGlassButton>
              )}
            </Stack>
          </Container>
        );
      case 3:
        return (
          <Container>
            <Stack gap={theme.spacing['2xl']} align="center">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {COACH_PHRASES.onboarding.step3}
              </Text>
              {isWaitingForUser && (
                <LiquidGlassButton
                  onPress={handleStep3}
                  disabled={isSpeaking}
                  variant="primary"
                  theme={theme}
                  textVariant="buttonLarge"
                >
                  Turn on the mic
                </LiquidGlassButton>
              )}
            </Stack>
          </Container>
        );
      default:
        return null;
    }
  };

  const renderMainContent = () => {
    if (onboardingStep !== 'complete') return null;

    return (
      <Container>
        <Stack gap={theme.spacing['2xl']} align="center">
          {isProcessingLLM ? (
            <Section marginTop="none">
              <Text variant="caption" align="center" style={{ maxWidth: '90%', color: theme.textSecondary }}>
                Thinking...
              </Text>
            </Section>
          ) : null}
{displayText ? (
            <Section marginTop="none">
              <Text variant="bodyLarge" align="center" style={{ maxWidth: '90%' }}>
                {displayText}
              </Text>
            </Section>
          ) : null}
          <Section marginTop="none">
            <Stack gap={theme.spacing.base} align="stretch">
              <LiquidGlassButton
                onPress={handleOption1}
                variant="secondary"
                theme={theme}
                textVariant="body"
              >
                {COACH_PHRASES.main.option1}
              </LiquidGlassButton>
              <LiquidGlassButton
                onPress={handleOption2}
                variant="secondary"
                theme={theme}
                textVariant="body"
              >
                {COACH_PHRASES.main.option2}
              </LiquidGlassButton>
            </Stack>
          </Section>
          <Section marginTop="none">
            <MicButtons
              theme={theme}
              isMuted={isMuted}
              onToggleMute={handleToggleMute}
            />
            {recognizedText ? (
              <View style={{ marginTop: theme.spacing.sm, paddingHorizontal: theme.spacing.base }}>
                <Text 
                  variant="caption" 
                  style={{ 
                    fontSize: 10, 
                    color: theme.textTertiary,
                    textAlign: 'center',
                    fontStyle: 'italic',
                  }}
                >
                  DEBUG: {recognizedText}
                </Text>
              </View>
            ) : null}
          </Section>
        </Stack>
      </Container>
    );
  };

  return (
    <ScreenContainer>
      <StatusBar style={theme.background === '#FFFFFF' ? 'dark' : 'light'} />
      {onboardingStep === 'complete' && (
        <LiquidGlassButton
          onPress={() => onOpenDrawer?.()}
          variant="secondary"
          theme={theme}
          style={styles.menuButton}
          borderRadius={24}
        >
          <Icon name="Bars3" size={28} color={theme.text} />
        </LiquidGlassButton>
      )}
      <View
        pointerEvents="none"
        style={styles.circleContainer}
      >
        <View style={[styles.blueCircle, { backgroundColor: theme.primary }]} />
      </View>
      <View style={styles.contentWrapper}>
        {onboardingStep !== 'complete' ? renderOnboardingContent() : renderMainContent()}
      </View>
    </ScreenContainer>
  );
};

const styles = StyleSheet.create({
  menuButton: {
    position: 'absolute',
    top: 50, // spacing['2xl'] + spacing.lg
    left: 20, // spacing.lg
    width: 48, // spacing['4xl']
    height: 48, // spacing['4xl']
    borderRadius: 24, // spacing['4xl'] / 2
    justifyContent: 'center',
    alignItems: 'center',
    zIndex: 1000,
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 4 }, // spacing.xs
    shadowOpacity: 0.15,
    shadowRadius: 8, // spacing.sm
    elevation: 8,
  },
  circleContainer: {
    position: 'absolute',
    top: 0,
    left: 0,
    right: 0,
    height: '50%',
    justifyContent: 'center',
    alignItems: 'center',
    zIndex: 1,
    backgroundColor: 'transparent',
  },
  blueCircle: {
    width: 100,
    height: 100,
    borderRadius: 50,
  },
  contentWrapper: {
    flex: 1,
    justifyContent: 'flex-end',
    paddingBottom: 40, // spacing['3xl']
    zIndex: 2,
    paddingTop: '50%', // –û—Ç—Å—Ç—É–ø —Å–≤–µ—Ä—Ö—É –¥–ª—è –∫–æ–Ω—Ç–µ–Ω—Ç–∞
  },
  bodyText: {
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É –∏–∑ theme
    textAlign: 'center',
    maxWidth: '90%',
  },
  button: {
    paddingHorizontal: 40, // spacing['3xl']
    paddingVertical: 18, // spacing.lg - spacing.xs
    borderRadius: 28, // spacing['2xl'] - spacing.xs
    minWidth: 140,
    alignItems: 'center',
    // shadowColor –ø—Ä–∏–º–µ–Ω—è–µ—Ç—Å—è –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏ —á–µ—Ä–µ–∑ inline style
    shadowOffset: { width: 0, height: 4 }, // spacing.xs
    shadowOpacity: 0.3,
    shadowRadius: 8, // spacing.sm
    elevation: 8,
  },
  buttonText: {
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É –∏–∑ theme, —Ü–≤–µ—Ç —á–µ—Ä–µ–∑ theme.primaryContrast
  },
  optionButton: {
    padding: 24, // spacing.xl
    borderRadius: 16, // spacing.base
    borderWidth: 1.5,
    alignItems: 'center',
    shadowColor: '#000',
    shadowOffset: { width: 0, height: 2 }, // spacing.xs / 2
    shadowOpacity: 0.1,
    shadowRadius: 4, // spacing.xs
    elevation: 3,
  },
  optionText: {
    // –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ç–∏–ø–æ–≥—Ä–∞—Ñ–∏–∫—É –∏–∑ theme
  },
});

